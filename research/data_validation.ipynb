{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Marina\\\\Desktop\\\\cicd-project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Schema Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the data that is going to be passed throught the pipeline has the same strucuture (range, categories names, name of the columns, non - null - values), of the data in which we trained the model and the pipeline. That way, we prevent future problems, and make sure, that our new data is going to fit the preprocessing pipeline, and the schema that our model expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandera as pa\n",
    "from pandera import Column, DataFrameSchema\n",
    "\n",
    "# Define the schema using the older syntax\n",
    "student_performance_schema = DataFrameSchema({\n",
    "    # Gender categories\n",
    "    \"gender\": Column(\n",
    "        str,\n",
    "        nullable=False,\n",
    "        checks=pa.Check.isin(['female', 'male'])\n",
    "    ),\n",
    "    \n",
    "    # Race/ethnicity categories\n",
    "    \"race_ethnicity\": Column(\n",
    "        str,\n",
    "        nullable=False,\n",
    "        checks=pa.Check.isin(['group A', 'group B', 'group C', 'group D', 'group E'])\n",
    "    ),\n",
    "    \n",
    "    # Parental education categories\n",
    "    \"parental_level_of_education\": Column(\n",
    "        str,\n",
    "        nullable=False,\n",
    "        checks=pa.Check.isin([\n",
    "            \"bachelor's degree\",\n",
    "            \"master's degree\",\n",
    "            \"associate's degree\",\n",
    "            \"some college\",\n",
    "            \"high school\",\n",
    "            \"some high school\"\n",
    "        ])\n",
    "    ),\n",
    "    \n",
    "    # Lunch categories\n",
    "    \"lunch\": Column(\n",
    "        str,\n",
    "        nullable=False,\n",
    "        checks=pa.Check.isin(['standard', 'free/reduced'])\n",
    "    ),\n",
    "    \n",
    "    # Test preparation categories\n",
    "    \"test_preparation_course\": Column(\n",
    "        str,\n",
    "        nullable=False,\n",
    "        checks=pa.Check.isin(['none', 'completed'])\n",
    "    ),\n",
    "    \n",
    "    # Numeric score columns\n",
    "    \"math_score\": Column(\n",
    "        int,\n",
    "        nullable=False,\n",
    "        checks=[\n",
    "            pa.Check.greater_than_or_equal_to(0),\n",
    "            pa.Check.less_than_or_equal_to(100)\n",
    "        ]\n",
    "    ),\n",
    "    \n",
    "    \"reading_score\": Column(\n",
    "        int,\n",
    "        nullable=False,\n",
    "        checks=[\n",
    "            pa.Check.greater_than_or_equal_to(0),\n",
    "            pa.Check.less_than_or_equal_to(100)\n",
    "        ]\n",
    "    ),\n",
    "    \n",
    "    \"writing_score\": Column(\n",
    "        int,\n",
    "        nullable=False,\n",
    "        checks=[\n",
    "            pa.Check.greater_than_or_equal_to(0),\n",
    "            pa.Check.less_than_or_equal_to(100)\n",
    "        ]\n",
    "    )\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Testcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./raw_data/students.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation successful!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    validated_schema_df = student_performance_schema.validate(df)\n",
    "    print(\"Validation successful!\")\n",
    "except pa.errors.SchemaError as e:\n",
    "    print(\"Validation failed!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Testcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wrong_df = pd.read_csv('./research/data_validation_wrong_schema.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation failed!\n",
      "Column 'race_ethnicity' failed element-wise validator number 0: isin(['group A', 'group B', 'group C', 'group D', 'group E']) failure cases: group F, group G\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    validated_df_wrong_df = student_performance_schema.validate(wrong_df)\n",
    "    print(\"Validation successful!\")\n",
    "except pa.errors.SchemaError as e:\n",
    "    print(\"Validation failed!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Cheking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for data depreciation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precomputing Reference Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.api.types as pd_types\n",
    "\n",
    "df = pd.read_csv(\"raw_data/students.csv\")\n",
    "\n",
    "# Identify numeric features using pandas API for types\n",
    "numeric_features = [col for col in df.columns if pd_types.is_numeric_dtype(df[col])]\n",
    "\n",
    "# Identify categorical features (objects or strings) using pandas API for types\n",
    "categorical_features = [col for col in df.columns if pd_types.is_object_dtype(df[col])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Example reference data\n",
    "reference_data = pd.read_csv(\"raw_data/students.csv\")\n",
    "\n",
    "# Compute statistics\n",
    "reference_stats = {}\n",
    "\n",
    "# Numerical features\n",
    "for feature in numeric_features:\n",
    "    reference_stats[feature] = {\n",
    "        \"mean\": reference_data[feature].mean(),\n",
    "        \"std\": reference_data[feature].std(),\n",
    "        \"percentiles\": reference_data[feature].quantile([0.25, 0.5, 0.75]).to_dict()\n",
    "    }\n",
    "\n",
    "# Categorical features\n",
    "for feature in categorical_features:\n",
    "    reference_stats[feature] = {\n",
    "        \"value_counts\": reference_data[feature].value_counts(normalize=True).to_dict(),\n",
    "    }\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"schemas/reference_stats.json\", \"w\") as f:\n",
    "    json.dump(reference_stats, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drift detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, Dict, Any\n",
    "\n",
    "def statistical_dataframe_validation(\n",
    "    data_frame_to_validate: pd.DataFrame, \n",
    "    reference_stats_path: Union[str, Dict[str, Any]],\n",
    "    numerical_tolerance: float = 3.0,\n",
    "    categorical_tolerance: float = 0.1\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Validate a DataFrame against reference statistics for data drift detection.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_frame_to_validate : pd.DataFrame\n",
    "        The DataFrame to be validated\n",
    "    reference_stats_path : str or dict\n",
    "        Path to JSON file or dictionary containing reference statistics\n",
    "    numerical_tolerance : float, optional\n",
    "        Number of standard deviations for numerical feature validation (default: 3.0)\n",
    "    categorical_tolerance : float, optional\n",
    "        Percentage difference tolerance for categorical features (default: 0.1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool\n",
    "        True if DataFrame passes validation, False otherwise\n",
    "    \"\"\"\n",
    "    # Load reference statistics\n",
    "    if isinstance(reference_stats_path, str):\n",
    "        with open(reference_stats_path, 'r') as f:\n",
    "            reference_stats = json.load(f)\n",
    "    else:\n",
    "        reference_stats = reference_stats_path\n",
    "    \n",
    "    # Validate each feature\n",
    "    for feature, stats in reference_stats.items():\n",
    "        # Skip if feature not in dataframe\n",
    "        if feature not in data_frame_to_validate.columns:\n",
    "            continue\n",
    "        \n",
    "        # Numerical feature validation\n",
    "        if 'mean' in stats:\n",
    "            feature_data = data_frame_to_validate[feature]\n",
    "            \n",
    "            # Check mean and standard deviation\n",
    "            current_mean = feature_data.mean()\n",
    "            current_std = feature_data.std()\n",
    "            \n",
    "            # Compare mean\n",
    "            mean_diff = abs(current_mean - stats['mean'])\n",
    "            if mean_diff > numerical_tolerance * stats['std']:\n",
    "                return False\n",
    "            \n",
    "            # Compare standard deviation\n",
    "            std_ratio = current_std / stats['std']\n",
    "            if std_ratio < 1/1.5 or std_ratio > 1.5:\n",
    "                return False\n",
    "            \n",
    "            # # Check percentile ranges\n",
    "            # percentiles = stats.get('percentiles', {})\n",
    "            # for percentile, ref_value in percentiles.items():\n",
    "            #     current_percentile = feature_data.quantile(float(percentile))\n",
    "            #     if abs(current_percentile - ref_value) > numerical_tolerance * stats['std']:\n",
    "            #         return False\n",
    "        \n",
    "        # Categorical feature validation\n",
    "        elif 'value_counts' in stats:\n",
    "            # Calculate current value counts\n",
    "            current_value_counts = data_frame_to_validate[feature].value_counts(normalize=True)\n",
    "            ref_value_counts = stats['value_counts']\n",
    "            \n",
    "            # Compare categorical distributions\n",
    "            for category, ref_proportion in ref_value_counts.items():\n",
    "                current_proportion = current_value_counts.get(category, 0)\n",
    "                if abs(current_proportion - ref_proportion) > categorical_tolerance:\n",
    "                    return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Completely different data distribution\n",
    "wrong_dist_df = pd.read_excel('research/data_validation_wrong_distribution.xlsx')\n",
    "stats_path = 'schemas/reference_stats.json'\n",
    "validated = statistical_dataframe_validation(wrong_dist_df, stats_path, 3, 0.1)\n",
    "validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sightly different data distribution\n",
    "sightly_diff_dist_df = pd.read_excel('research/data_validation_sightly_different_dist.xlsx')\n",
    "stats_path = 'schemas/reference_stats.json'\n",
    "validated = statistical_dataframe_validation(sightly_diff_dist_df, stats_path, 3, 0.1)\n",
    "validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sightly different data distribution, with lower treshold\n",
    "sightly_diff_dist_df = pd.read_excel('research/data_validation_sightly_different_dist.xlsx')\n",
    "stats_path = 'schemas/reference_stats.json'\n",
    "validated = statistical_dataframe_validation(sightly_diff_dist_df, stats_path, 0.3, 0.1)\n",
    "validated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-cicd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
